<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ | BLOG</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://perfectqing.github.io/blogs/favicon.ico?v=1626771746855">
<link rel="stylesheet" href="https://perfectqing.github.io/blogs/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="ğŸ‘  ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ
âœï¸  æœ¬è®²ç›®æ ‡ï¼šç”¨RNNå®ç°è¿ç»­æ•°æ®çš„é¢„æµ‹ï¼ˆä»¥è‚¡ç¥¨é¢„æµ‹ä¸ºä¾‹ï¼‰ã€å›é¡¾å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œã€å®è·µï¼šABCDEå­—æ¯é¢„æµ‹ã€å®è·µï¼šè‚¡ç¥¨é¢„æµ‹

ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ
æœ¬è®²ç›®æ ‡ï¼šç”¨RNNå®ç°è¿ç»­æ•°æ®çš„é¢„æµ‹ï¼ˆä»¥è‚¡ç¥¨é¢„æµ‹..." />
    <meta name="keywords" content="TensorFlow ç¬”è®°" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://perfectqing.github.io/blogs">
        <img src="https://perfectqing.github.io/blogs/images/avatar.png?v=1626771746855" class="site-logo">
        <h1 class="site-title">BLOG</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            é¦–é¡µ
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            å½’æ¡£
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            æ ‡ç­¾
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            å…³äº
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      Carry on what you want...
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> Copyright Â© AlsoRan | <a class="rss" href="https://perfectqing.github.io/blogs/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ</h2>
            <div class="post-date">2021-07-19</div>
            
              <div class="feature-container" style="background-image: url('https://perfectqing.github.io/blogs/post-images/ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ.png')">
              </div>
            
            <div class="post-content" v-pre>
              <p>ğŸ‘  ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ<br>
âœï¸  æœ¬è®²ç›®æ ‡ï¼šç”¨RNNå®ç°è¿ç»­æ•°æ®çš„é¢„æµ‹ï¼ˆä»¥è‚¡ç¥¨é¢„æµ‹ä¸ºä¾‹ï¼‰ã€å›é¡¾å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œã€å®è·µï¼šABCDEå­—æ¯é¢„æµ‹ã€å®è·µï¼šè‚¡ç¥¨é¢„æµ‹</p>
<!-- more -->
<h3 id="ç¬¬å…­ç« -å¾ªç¯ç¥ç»ç½‘ç»œ">ç¬¬å…­ç«  å¾ªç¯ç¥ç»ç½‘ç»œ</h3>
<p>æœ¬è®²ç›®æ ‡ï¼šç”¨RNNå®ç°è¿ç»­æ•°æ®çš„é¢„æµ‹ï¼ˆä»¥è‚¡ç¥¨é¢„æµ‹ä¸ºä¾‹ï¼‰</p>
<ol>
<li>
<p>å›é¡¾å·ç§¯ç¥ç»ç½‘ç»œ</p>
</li>
<li>
<p>å¾ªç¯ç¥ç»ç½‘ç»œ</p>
<ul>
<li>å¾ªç¯æ ¸</li>
<li>å¾ªç¯æ ¸æ—¶é—´æ­¥å±•å¼€</li>
<li>å¾ªç¯è®¡ç®—å±‚</li>
<li>TFæè¿°å¾ªç¯è®¡ç®—å±‚</li>
<li>å¾ªç¯è®¡ç®—è¿‡ç¨‹</li>
</ul>
</li>
<li>
<p>å®è·µï¼šABCDEå­—æ¯é¢„æµ‹</p>
<ul>
<li>One-hot</li>
<li>Emebedding</li>
</ul>
</li>
<li>
<p>å®è·µï¼šè‚¡ç¥¨é¢„æµ‹</p>
<ul>
<li>RNN</li>
<li>LSTM</li>
<li>GRU</li>
</ul>
</li>
</ol>
<h4 id="61-å›é¡¾å·ç§¯ç¥ç»ç½‘ç»œ">6.1 å›é¡¾å·ç§¯ç¥ç»ç½‘ç»œ</h4>
<ul>
<li>
<p>å·ç§¯æ ¸ï¼šå‚æ•°ç©ºé—´å…±äº«ï¼Œå·ç§¯å±‚æå–ç©ºé—´ä¿¡æ¯ã€‚</p>
<ol>
<li>
<p>å·ç§¯ç¥ç»ç½‘ç»œçš„ä¸»è¦æ¨¡å—</p>
<p>å·ç§¯(Convolutional)ã€æ‰¹æ ‡å‡†åŒ–(BN)ã€æ¿€æ´»(Activation)ã€æ± åŒ–(Pooling)ã€å…¨è¿æ¥(FC)</p>
</li>
<li>
<p>å·ç§¯æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<p>å·ç§¯å°±æ˜¯ç‰¹å¾æå–å™¨ï¼Œå°±æ˜¯CBAPD</p>
</li>
</ol>
<blockquote>
<p>å·ç§¯ç¥ç»ç½‘ç»œï¼šå€ŸåŠ©å·ç§¯æ ¸æå–ç©ºé—´ç‰¹å¾åï¼Œé€å…¥å…¨è¿æ¥ç½‘ç»œã€‚</p>
</blockquote>
</li>
</ul>
<h4 id="62-å¾ªç¯ç¥ç»ç½‘ç»œ">6.2 å¾ªç¯ç¥ç»ç½‘ç»œ</h4>
<ul>
<li>
<p>å¾ªç¯æ ¸ï¼šå‚æ•°æ—¶é—´å…±äº«ï¼Œå¾ªç¯å±‚æå–æ—¶é—´ä¿¡æ¯ã€‚</p>
<p>é€šè¿‡ä¸åŒæ—¶åˆ»çš„å‚æ•°å…±äº«ï¼Œå®ç°å¯¹æ—¶é—´åºåˆ—çš„ä¿¡æ¯æå–ã€‚</p>
<figure data-type="image" tabindex="1"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107181002296-1.png" alt="6-1" loading="lazy"></figure>
<p>å‰å‘ä¼ æ’­æ—¶ï¼šè®°å¿†ä½“å†…å­˜å‚¨çš„çŠ¶æ€ä¿¡æ¯<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>ï¼Œåœ¨æ¯ä¸ªæ—¶åˆ»éƒ½è¢«åˆ·æ–°ï¼Œä¸‰ä¸ªå‚æ•°çŸ©é˜µ<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{xh},  w_{hh}, w_{hy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>è‡ªå§‹è‡³ç»ˆéƒ½æ˜¯å›ºå®šä¸å˜çš„ã€‚</p>
<p>åå‘ä¼ æ’­æ—¶ï¼šä¸‰ä¸ªå‚æ•°çŸ©é˜µ<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{xh},  w_{hh}, w_{hy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>è¢«æ¢¯åº¦ä¸‹é™æ³•æ›´æ–°ã€‚</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><msub><mi>h</mi><mi>t</mi></msub><msub><mi>w</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>y</mi></msub><mo>)</mo><mspace linebreak="newline"></mspace><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><msub><mi>w</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><mo>+</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><msub><mi>w</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">y_t=softmax(h_tw_{hy}+b_y)\\
h_t=tanh(x_tw_{xh}+h_{t-1}w_{hh}+b_h
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>
<p>å¾ªç¯æ ¸æŒ‰æ—¶é—´æ­¥å±•å¼€</p>
<p>æŒ‰ç…§æ—¶é—´æ­¥å±•å¼€ï¼Œå°±æ˜¯æŠŠå¾ªç¯æ ¸æŒ‰ç…§æ—¶é—´è½´æ–¹å‘å±•å¼€ã€‚æ¯ä¸ªæ—¶åˆ»è®°å¿†ä½“çŠ¶æ€ä¿¡æ¯<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>è¢«åˆ·æ–°ï¼Œå‘¨å›´çš„å‚æ•°çŸ©é˜µå›ºå®šä¸å˜ã€‚</p>
<figure data-type="image" tabindex="2"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230196-2.png" alt="6-2" loading="lazy"></figure>
<blockquote>
<p>å¾ªç¯ç¥ç»ç½‘ç»œï¼šå€ŸåŠ©å¾ªç¯æ ¸æå–æ—¶é—´ç‰¹å¾åï¼Œé€å…¥å…¨è¿æ¥ç½‘ç»œã€‚</p>
</blockquote>
</li>
<li>
<p>å¾ªç¯è®¡ç®—å±‚ï¼šå‘è¾“å‡ºæ–¹å‘ç”Ÿé•¿</p>
<figure data-type="image" tabindex="3"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230256-3.png" alt="6-3" loading="lazy"></figure>
<blockquote>
<p>æ¯ä¸ªå¾ªç¯æ ¸ä¸­è®°å¿†ä½“çš„ä¸ªæ•°æ˜¯æ ¹æ®éœ€æ±‚ä»»æ„æŒ‡å®šçš„ã€‚</p>
</blockquote>
</li>
<li>
<p>TFæè¿°å¾ªç¯è®¡ç®—å±‚</p>
<pre><code class="language-python">tf.keras.layers.SimpleRNN(è®°å¿†ä½“ä¸ªæ•°, activation='æ¿€æ´»å‡½æ•°', return_sequences=æ˜¯å¦æ¯ä¸ªæ—¶åˆ»è¾“å‡ºhtåˆ°ä¸‹ä¸€å±‚)

activation='æ¿€æ´»å‡½æ•°'  # ä¸å†™é»˜è®¤ä½¿ç”¨tanh
return_sequences=True  # å„æ—¶é—´æ­¥è¾“å‡ºht
return_sequences=False  # ä»…æœ€åæ—¶é—´æ­¥è¾“å‡ºhtï¼ˆé»˜è®¤ï¼‰

# Example
SimpleRNN(3, return_sequences=True)  # å®šä¹‰ä¸€ä¸ªæœ‰ä¸‰ä¸ªè®°å¿†ä½“çš„å¾ªç¯æ ¸ï¼Œæ¯ä¸ªæ—¶é—´æ­¥è¾“å‡ºht
</code></pre>
<p><code>return_sequences=True</code> å¾ªç¯æ ¸å„æ—¶åˆ»ä¼šæŠŠhtæ¨é€åˆ°ä¸‹ä¸€å±‚</p>
<figure data-type="image" tabindex="4"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230316-4.png" alt="6-4" loading="lazy"></figure>
<p><code>return_sequences=False</code> å¾ªç¯æ ¸ä»…åœ¨æœ€åä¸€ä¸ªæ—¶åˆ»æŠŠhtæ¨é€åˆ°ä¸‹ä¸€å±‚</p>
<figure data-type="image" tabindex="5"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230376-5.png" alt="6-5" loading="lazy"></figure>
<ul>
<li>
<p>é€å…¥RNNæ—¶ï¼Œx_trainç»´åº¦ï¼š</p>
<p>[é€å…¥æ ·æœ¬æ•°, å¾ªç¯æ ¸æ—¶é—´æ­¥å±•å¼€æ­¥æ•°, æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]</p>
<p>Exampleï¼š</p>
<figure data-type="image" tabindex="6"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230436-6.png" alt="6-6" loading="lazy"></figure>
<p>å·¦è¾¹<strong>2</strong>ç»„æ•°æ®ï¼Œæ¯ç»„æ•°æ®ç»è¿‡<strong>1</strong>ä¸ªæ—¶é—´æ­¥å°±ä¼šå¾—åˆ°è¾“å‡ºç»“æœï¼Œæ¯ä¸ªæ—¶é—´æ­¥é€å…¥<strong>3</strong>ä¸ªæ•°å€¼ã€‚  [2, 1, 3]<br>
å³è¾¹åªæœ‰ä¸€ç»„æ•°æ®ï¼Œåˆ†å››ä¸ªæ—¶é—´æ­¥é€å…¥å¾ªç¯å±‚ï¼Œæ¯ä¸ªæ—¶é—´æ­¥é€å…¥ä¸¤ä¸ªæ•°å€¼ã€‚  [1, 4, 2]</p>
</li>
</ul>
</li>
</ul>
<h4 id="63-å®è·µå­—æ¯é¢„æµ‹">6.3 å®è·µï¼šå­—æ¯é¢„æµ‹</h4>
<ul>
<li>
<p>å¾ªç¯è®¡ç®—è¿‡ç¨‹â… ï¼ˆå­—æ¯é¢„æµ‹ä¸ºä¾‹å­ï¼Œè¾“å…¥ä¸€ä¸ªå­—æ¯é¢„æµ‹ä¸‹ä¸€ä¸ªï¼‰</p>
<p>å­—æ¯é¢„æµ‹ï¼šè¾“å…¥aé¢„æµ‹å‡ºbï¼Œè¾“å…¥bé¢„æµ‹å‡ºcï¼Œè¾“å…¥cé¢„æµ‹å‡ºdï¼Œè¾“å…¥dé¢„æµ‹å‡ºeï¼Œè¾“å…¥eé¢„æµ‹å‡ºaã€‚</p>
<p>è¯å‘é‡ç©ºé—´ï¼šï¼ˆç‹¬çƒ­ç è¡¨ç¤ºï¼‰</p>
<table>
<thead>
<tr>
<th style="text-align:center">ç‹¬çƒ­ç </th>
<th style="text-align:center">å­—æ¯</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">10000</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">01000</td>
<td style="text-align:center">b</td>
</tr>
<tr>
<td style="text-align:center">00100</td>
<td style="text-align:center">c</td>
</tr>
<tr>
<td style="text-align:center">00010</td>
<td style="text-align:center">d</td>
</tr>
<tr>
<td style="text-align:center">00001</td>
<td style="text-align:center">e</td>
</tr>
</tbody>
</table>
<p>éšæœºç”Ÿæˆ<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{xh},  w_{hh}, w_{hy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></p>
<pre><code class="language-python"># Why
[[-1.7  0.7 -1.7 1.7  0.7]
 [-1.6 -1.6  0.7 1.7  0.7]
 [-1.4  1.9  1.2 1.7 -1.9]]
# by
[0.0 0.1 0.4 -0.7 0.1]

# Whh
[[-0.9 -0.2 -0.4]
 [-0.3  0.9  0.2]
 [ 0.4  0.3 -0.9]]

# Why
[[ 0.5 -1.7  1.7]
 [-2.3  0.8  1.1]
 [ 1.3  1.7  1.4]
 [ 0.3  0.8 -1.1]
 [-1.8 -2.0 -1.0]]
# bh
[0.5 0.3 -0.2]

# ht
[0.0 0.0 0.0]
</code></pre>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><msub><mi>w</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><mo>+</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><msub><mi>w</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">h_t=tanh(x_tw_{xh}+h_{t-1}w_{hh}+b_h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<figure data-type="image" tabindex="7"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230486-7.png" alt="6-7" loading="lazy"></figure>
</li>
<li>
<p>ç”¨RNNå®ç°è¾“å…¥ä¸€ä¸ªå­—æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå­—æ¯ä»£ç ï¼ˆOne hot ç¼–ç ï¼‰</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, SimpleRNN
import matplotlib.pyplot as plt
import os

input_word = &quot;abcde&quot;
w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}  # å•è¯æ˜ å°„åˆ°æ•°å€¼idçš„è¯å…¸
id_to_onehot = {0: [1., 0., 0., 0., 0.], 1: [0., 1., 0., 0., 0.], 2: [0., 0., 1., 0., 0.], 3: [0., 0., 0., 1., 0.],
                4: [0., 0., 0., 0., 1.]}  # idç¼–ç ä¸ºone-hot

x_train = [id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']],
           id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']]]
y_train = [w_to_id['b'], w_to_id['c'], w_to_id['d'], w_to_id['e'], w_to_id['a']]

np.random.seed(7)
np.random.shuffle(x_train)
np.random.seed(7)
np.random.shuffle(y_train)
tf.random.set_seed(7)

# ä½¿x_trainç¬¦åˆSimpleRNNè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ï¼Œ æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]ã€‚
# æ­¤å¤„æ•´ä¸ªæ•°æ®é›†é€å…¥ï¼Œé€å…¥æ ·æœ¬æ•°ä¸ºlen(x_train)ï¼›è¾“å…¥1ä¸ªå­—æ¯å‡ºç»“æœï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º1; è¡¨ç¤ºä¸ºç‹¬çƒ­ç æœ‰5ä¸ªè¾“å…¥ç‰¹å¾ï¼Œæ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°ä¸º5
x_train = np.reshape(x_train, (len(x_train), 1, 5))
y_train = np.array(y_train)

model = tf.keras.Sequential([
    SimpleRNN(3),  # å…·æœ‰ä¸‰ä¸ªè®°å¿†ä½“çš„å¾ªç¯å±‚
    Dense(5, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.01),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])

checkpoint_save_path = &quot;./checkpoint/rnn_onehot_1pre1.ckpt&quot;

if os.path.exists(checkpoint_save_path + '.index'):
    print('-------------load the model-----------------')
    model.load_weights(checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True,
                                                 monitor='loss')  # ç”±äºfitæ²¡æœ‰ç»™å‡ºæµ‹è¯•é›†ï¼Œä¸è®¡ç®—æµ‹è¯•é›†å‡†ç¡®ç‡ï¼Œæ ¹æ®lossï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹

history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])

model.summary()

# print(model.trainable_variables)
file = open('./weights.txt', 'w')  # å‚æ•°æå–
for v in model.trainable_variables:
    file.write(str(v.name) + '\n')
    file.write(str(v.shape) + '\n')
    file.write(str(v.numpy()) + '\n')
file.close()

###############################################    show   ###############################################

# æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„accå’Œlossæ›²çº¿
acc = history.history['sparse_categorical_accuracy']
loss = history.history['loss']

plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.title('Training Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.title('Training Loss')
plt.legend()
plt.show()

############### predict #############

preNum = int(input(&quot;input the number of test alphabet:&quot;))
for i in range(preNum):
    alphabet1 = input(&quot;input test alphabet:&quot;)
    alphabet = [id_to_onehot[w_to_id[alphabet1]]]
    # ä½¿alphabetç¬¦åˆSimpleRNNè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ï¼Œ æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]ã€‚æ­¤å¤„éªŒè¯æ•ˆæœé€å…¥äº†1ä¸ªæ ·æœ¬ï¼Œé€å…¥æ ·æœ¬æ•°ä¸º1ï¼›è¾“å…¥1ä¸ªå­—æ¯å‡ºç»“æœï¼Œæ‰€ä»¥å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º1; è¡¨ç¤ºä¸ºç‹¬çƒ­ç æœ‰5ä¸ªè¾“å…¥ç‰¹å¾ï¼Œæ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°ä¸º5
    alphabet = np.reshape(alphabet, (1, 1, 5))
    result = model.predict([alphabet])
    pred = tf.argmax(result, axis=1)
    pred = int(pred)
    tf.print(alphabet1 + '-&gt;' + input_word[pred])

# è¿è¡Œç»“æœ
# Epoch 100/100
# 1/1 [==============================] - 0s 3ms/step - loss: 0.4303 - sparse_categorical_accuracy: 1.0000
# Model: &quot;sequential&quot;
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #   
# =================================================================
# simple_rnn (SimpleRNN)       (None, 3)                 27        
# _________________________________________________________________
# dense (Dense)                (None, 5)                 20        
# =================================================================
# Total params: 47
# Trainable params: 47
# Non-trainable params: 0
# _________________________________________________________________
# input the number of test alphabet:2
# 2
# input test alphabet:a
# a
# a-&gt;b
# input test alphabet:d
# d
# d-&gt;e
</code></pre>
</li>
<li>
<p>å¾ªç¯è®¡ç®—è¿‡ç¨‹â…¡ï¼ˆå­—æ¯é¢„æµ‹ä¾‹å­ï¼Œè¾“å…¥å¤šä¸ªå­—æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå­—æ¯ï¼‰</p>
<p>è¿ç»­è¾“å…¥å››ä¸ªå­—æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå­—æ¯ã€‚</p>
<p>ä½¿ç”¨ä¸‰ä¸ªè®°å¿†ä½“ã€‚</p>
<figure data-type="image" tabindex="8"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191230546-8.png" alt="6-8" loading="lazy"></figure>
</li>
<li>
<p>ç”¨RNNå®ç°è¾“å…¥è¿ç»­å››ä¸ªå­—æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå­—æ¯ï¼ˆOne hotç¼–ç ï¼‰</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, SimpleRNN
import matplotlib.pyplot as plt
import os

input_word = &quot;abcde&quot;
w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}  # å•è¯æ˜ å°„åˆ°æ•°å€¼idçš„è¯å…¸
id_to_onehot = {0: [1., 0., 0., 0., 0.], 1: [0., 1., 0., 0., 0.], 2: [0., 0., 1., 0., 0.], 3: [0., 0., 0., 1., 0.],
                4: [0., 0., 0., 0., 1.]}  # idç¼–ç ä¸ºone-hot

x_train = [
    [id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']], id_to_onehot[w_to_id['d']]],
    [id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']], id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']]],
    [id_to_onehot[w_to_id['c']], id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']], id_to_onehot[w_to_id['a']]],
    [id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']], id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']]],
    [id_to_onehot[w_to_id['e']], id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']]],
]
y_train = [w_to_id['e'], w_to_id['a'], w_to_id['b'], w_to_id['c'], w_to_id['d']]

np.random.seed(7)
np.random.shuffle(x_train)
np.random.seed(7)
np.random.shuffle(y_train)
tf.random.set_seed(7)

# ä½¿x_trainç¬¦åˆSimpleRNNè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ï¼Œ æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]ã€‚
# æ­¤å¤„æ•´ä¸ªæ•°æ®é›†é€å…¥ï¼Œé€å…¥æ ·æœ¬æ•°ä¸ºlen(x_train)ï¼›è¾“å…¥4ä¸ªå­—æ¯å‡ºç»“æœï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º4; è¡¨ç¤ºä¸ºç‹¬çƒ­ç æœ‰5ä¸ªè¾“å…¥ç‰¹å¾ï¼Œæ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°ä¸º5
x_train = np.reshape(x_train, (len(x_train), 4, 5))
y_train = np.array(y_train)

model = tf.keras.Sequential([
    SimpleRNN(3),
    Dense(5, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.01),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])

checkpoint_save_path = &quot;./checkpoint/rnn_onehot_4pre1.ckpt&quot;

if os.path.exists(checkpoint_save_path + '.index'):
    print('-------------load the model-----------------')
    model.load_weights(checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True,
                                                 monitor='loss')  # ç”±äºfitæ²¡æœ‰ç»™å‡ºæµ‹è¯•é›†ï¼Œä¸è®¡ç®—æµ‹è¯•é›†å‡†ç¡®ç‡ï¼Œæ ¹æ®lossï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹

history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])

model.summary()

# print(model.trainable_variables)
file = open('./weights.txt', 'w')  # å‚æ•°æå–
for v in model.trainable_variables:
    file.write(str(v.name) + '\n')
    file.write(str(v.shape) + '\n')
    file.write(str(v.numpy()) + '\n')
file.close()

###############################################    show   ###############################################

# æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„accå’Œlossæ›²çº¿
acc = history.history['sparse_categorical_accuracy']
loss = history.history['loss']

plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.title('Training Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.title('Training Loss')
plt.legend()
plt.show()

############### predict #############

preNum = int(input(&quot;input the number of test alphabet:&quot;))
for i in range(preNum):
    alphabet1 = input(&quot;input test alphabet:&quot;)
    alphabet = [id_to_onehot[w_to_id[a]] for a in alphabet1]
    # ä½¿alphabetç¬¦åˆSimpleRNNè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ï¼Œ æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]ã€‚æ­¤å¤„éªŒè¯æ•ˆæœé€å…¥äº†1ä¸ªæ ·æœ¬ï¼Œé€å…¥æ ·æœ¬æ•°ä¸º1ï¼›è¾“å…¥4ä¸ªå­—æ¯å‡ºç»“æœï¼Œæ‰€ä»¥å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º4; è¡¨ç¤ºä¸ºç‹¬çƒ­ç æœ‰5ä¸ªè¾“å…¥ç‰¹å¾ï¼Œæ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°ä¸º5
    alphabet = np.reshape(alphabet, (1, 4, 5))
    result = model.predict([alphabet])
    pred = tf.argmax(result, axis=1)
    pred = int(pred)
    tf.print(alphabet1 + '-&gt;' + input_word[pred])

# è¿è¡Œç»“æœ
# Epoch 100/100
# 1/1 [==============================] - 0s 4ms/step - loss: 0.0846 - sparse_categorical_accuracy: 1.0000
# Model: &quot;sequential&quot;
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #   
# =================================================================
# simple_rnn (SimpleRNN)       (None, 3)                 27        
# _________________________________________________________________
# dense (Dense)                (None, 5)                 20        
# =================================================================
# Total params: 47
# Trainable params: 47
# Non-trainable params: 0
# _________________________________________________________________
# input the number of test alphabet:5
# 5
# input test alphabet:abcd
# abcd
# abcd-&gt;e
# input test alphabet:bcde
# bcde
# bcde-&gt;a
# input test alphabet:cdea
# cdea
# cdea-&gt;b
# input test alphabet:deab
# deab
# deab-&gt;c
# input test alphabet:eabc
# eabc
# eabc-&gt;d
# 
# Process finished with exit code 0
</code></pre>
</li>
<li>
<p>Embeddingç¼–ç </p>
<p>ç‹¬çƒ­ç ï¼šæ•°æ®é‡å¤§ï¼Œè¿‡äºç¨€ç–ï¼Œæ˜ å°„ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œæ²¡æœ‰è¡¨ç°å‡ºå…³è”æ€§ã€‚<br>
Embeddingï¼šæ˜¯ä¸€ç§å•è¯ç¼–ç æ–¹æ³•ï¼Œç”¨ä½ç»´å‘é‡å®ç°äº†ç¼–ç ï¼Œè¿™ç§ç¼–ç é€šè¿‡ç¥ç»ç½‘ç»œè®­ç»ƒä¼˜åŒ–ï¼Œèƒ½è¡¨è¾¾å‡ºå•è¯é—´çš„ç›¸å…³æ€§ã€‚</p>
<pre><code class="language-python">tf.keras.layers.Embedding(è¯æ±‡è¡¨å¤§å°, ç¼–ç ä¸ºåº¦)
# è¯æ±‡è¡¨å¤§å°å°±æ˜¯ä¸€å…±è¦è¡¨ç¤ºå¤šå°‘ä¸ªå•è¯
# ç¼–ç ç»´åº¦å°±æ˜¯ç”¨å‡ ä¸ªæ•°å­—è¡¨è¾¾ä¸€ä¸ªå•è¯
# å¯¹1-100è¿›è¡Œç¼–ç ï¼Œå…¶ä¸­[4]ç¼–ç ä¸º [0.25, 0.1, 0.11]
# å¦‚ä¸‹ä¾‹å­
tf.keras.layers.Embedding(100, 3)
</code></pre>
<p>è¾“å…¥Embeddingæ—¶ï¼Œx_trainç»´åº¦ï¼š[é€å…¥æ ·æœ¬æ•°, å¾ªç¯æ ¸äº‹ä»¶å±•å¼€æ­¥æ•°]</p>
</li>
<li>
<p>ç”¨RNNå®ç°è¾“å…¥ä¸€ä¸ªå­—æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå­—æ¯ï¼ˆEmbeddingç¼–ç ï¼‰</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, SimpleRNN, Embedding
import matplotlib.pyplot as plt
import os

input_word = &quot;abcde&quot;
w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}  # å•è¯æ˜ å°„åˆ°æ•°å€¼idçš„è¯å…¸

x_train = [w_to_id['a'], w_to_id['b'], w_to_id['c'], w_to_id['d'], w_to_id['e']]
y_train = [w_to_id['b'], w_to_id['c'], w_to_id['d'], w_to_id['e'], w_to_id['a']]

np.random.seed(7)
np.random.shuffle(x_train)
np.random.seed(7)
np.random.shuffle(y_train)
tf.random.set_seed(7)

# ä½¿x_trainç¬¦åˆEmbeddingè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°] ï¼Œ
# æ­¤å¤„æ•´ä¸ªæ•°æ®é›†é€å…¥æ‰€ä»¥é€å…¥ï¼Œé€å…¥æ ·æœ¬æ•°ä¸ºlen(x_train)ï¼›è¾“å…¥1ä¸ªå­—æ¯å‡ºç»“æœï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º1ã€‚
x_train = np.reshape(x_train, (len(x_train), 1))
y_train = np.array(y_train)

model = tf.keras.Sequential([
    Embedding(5, 2),
    SimpleRNN(3),
    Dense(5, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.01),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])

checkpoint_save_path = &quot;./checkpoint/run_embedding_1pre1.ckpt&quot;

if os.path.exists(checkpoint_save_path + '.index'):
    print('-------------load the model-----------------')
    model.load_weights(checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True,
                                                 monitor='loss')  # ç”±äºfitæ²¡æœ‰ç»™å‡ºæµ‹è¯•é›†ï¼Œä¸è®¡ç®—æµ‹è¯•é›†å‡†ç¡®ç‡ï¼Œæ ¹æ®lossï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹

history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])

model.summary()

# print(model.trainable_variables)
file = open('./weights.txt', 'w')  # å‚æ•°æå–
for v in model.trainable_variables:
    file.write(str(v.name) + '\n')
    file.write(str(v.shape) + '\n')
    file.write(str(v.numpy()) + '\n')
file.close()

###############################################    show   ###############################################

# æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„accå’Œlossæ›²çº¿
acc = history.history['sparse_categorical_accuracy']
loss = history.history['loss']

plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.title('Training Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.title('Training Loss')
plt.legend()
plt.show()

############### predict #############

preNum = int(input(&quot;input the number of test alphabet:&quot;))
for i in range(preNum):
    alphabet1 = input(&quot;input test alphabet:&quot;)
    alphabet = [w_to_id[alphabet1]]
    # ä½¿alphabetç¬¦åˆEmbeddingè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°]ã€‚
    # æ­¤å¤„éªŒè¯æ•ˆæœé€å…¥äº†1ä¸ªæ ·æœ¬ï¼Œé€å…¥æ ·æœ¬æ•°ä¸º1ï¼›è¾“å…¥1ä¸ªå­—æ¯å‡ºç»“æœï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º1ã€‚
    alphabet = np.reshape(alphabet, (1, 1))
    result = model.predict(alphabet)
    pred = tf.argmax(result, axis=1)
    pred = int(pred)
    tf.print(alphabet1 + '-&gt;' + input_word[pred])

# è¿è¡Œç»“æœ
# Epoch 100/100
# 1/1 [==============================] - 0s 3ms/step - loss: 0.6305 - sparse_categorical_accuracy: 1.0000
# Model: &quot;sequential&quot;
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #
# =================================================================
# embedding (Embedding)        (None, None, 2)           10
# _________________________________________________________________
# simple_rnn (SimpleRNN)       (None, 3)                 18
# _________________________________________________________________
# dense (Dense)                (None, 5)                 20
# =================================================================
# Total params: 48
# Trainable params: 48
# Non-trainable params: 0
# _________________________________________________________________
# input the number of test alphabet:2
# 2
# input test alphabet:a
# a
# a-&gt;b
# input test alphabet:e
# e
# e-&gt;a
#
# Process finished with exit code 0
</code></pre>
</li>
<li>
<p>ç”¨RNNå®ç°è¾“å…¥è¿ç»­å››ä¸ªå­—æ¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå­—æ¯ï¼ˆEmbeddingç¼–ç ï¼‰</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, SimpleRNN, Embedding
import matplotlib.pyplot as plt
import os

input_word = &quot;abcdefghijklmnopqrstuvwxyz&quot;
w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4,
           'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9,
           'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14,
           'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19,
           'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}  # å•è¯æ˜ å°„åˆ°æ•°å€¼idçš„è¯å…¸

training_set_scaled = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
                       11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
                       21, 22, 23, 24, 25]

x_train = []
y_train = []

for i in range(4, 26):
    x_train.append(training_set_scaled[i - 4:i])
    y_train.append(training_set_scaled[i])

np.random.seed(7)
np.random.shuffle(x_train)
np.random.seed(7)
np.random.shuffle(y_train)
tf.random.set_seed(7)

# ä½¿x_trainç¬¦åˆEmbeddingè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°] ï¼Œ
# æ­¤å¤„æ•´ä¸ªæ•°æ®é›†é€å…¥æ‰€ä»¥é€å…¥ï¼Œé€å…¥æ ·æœ¬æ•°ä¸ºlen(x_train)ï¼›è¾“å…¥4ä¸ªå­—æ¯å‡ºç»“æœï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º4ã€‚
x_train = np.reshape(x_train, (len(x_train), 4))
y_train = np.array(y_train)

model = tf.keras.Sequential([
    Embedding(26, 2),
    SimpleRNN(10),
    Dense(26, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.01),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])

checkpoint_save_path = &quot;./checkpoint/rnn_embedding_4pre1.ckpt&quot;

if os.path.exists(checkpoint_save_path + '.index'):
    print('-------------load the model-----------------')
    model.load_weights(checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True,
                                                 monitor='loss')  # ç”±äºfitæ²¡æœ‰ç»™å‡ºæµ‹è¯•é›†ï¼Œä¸è®¡ç®—æµ‹è¯•é›†å‡†ç¡®ç‡ï¼Œæ ¹æ®lossï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹

history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])

model.summary()

file = open('./weights.txt', 'w')  # å‚æ•°æå–
for v in model.trainable_variables:
    file.write(str(v.name) + '\n')
    file.write(str(v.shape) + '\n')
    file.write(str(v.numpy()) + '\n')
file.close()

###############################################    show   ###############################################

# æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„accå’Œlossæ›²çº¿
acc = history.history['sparse_categorical_accuracy']
loss = history.history['loss']

plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.title('Training Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.title('Training Loss')
plt.legend()
plt.show()

################# predict ##################

preNum = int(input(&quot;input the number of test alphabet:&quot;))
for i in range(preNum):
    alphabet1 = input(&quot;input test alphabet:&quot;)
    alphabet = [w_to_id[a] for a in alphabet1]
    # ä½¿alphabetç¬¦åˆEmbeddingè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ æ—¶é—´å±•å¼€æ­¥æ•°]ã€‚
    # æ­¤å¤„éªŒè¯æ•ˆæœé€å…¥äº†1ä¸ªæ ·æœ¬ï¼Œé€å…¥æ ·æœ¬æ•°ä¸º1ï¼›è¾“å…¥4ä¸ªå­—æ¯å‡ºç»“æœï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º4ã€‚
    alphabet = np.reshape(alphabet, (1, 4))
    result = model.predict([alphabet])
    pred = tf.argmax(result, axis=1)
    pred = int(pred)
    tf.print(alphabet1 + '-&gt;' + input_word[pred])

# è¿è¡Œç»“æœ
# Epoch 100/100
# 1/1 [==============================] - 0s 5ms/step - loss: 0.1948 - sparse_categorical_accuracy: 1.0000
# Model: &quot;sequential&quot;
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #
# =================================================================
# embedding (Embedding)        (None, None, 2)           52
# _________________________________________________________________
# simple_rnn (SimpleRNN)       (None, 10)                130
# _________________________________________________________________
# dense (Dense)                (None, 26)                286
# =================================================================
# Total params: 468
# Trainable params: 468
# Non-trainable params: 0
# _________________________________________________________________
# input the number of test alphabet:2
# 2
# input test alphabet:abcd
# abcd
# abcd-&gt;e
# input test alphabet:hijk
# hijk
# hijk-&gt;l
</code></pre>
</li>
</ul>
<h4 id="64-å®è·µè‚¡ç¥¨é¢„æµ‹">6.4 å®è·µï¼šè‚¡ç¥¨é¢„æµ‹</h4>
<ul>
<li>
<p>æ•°æ®æº</p>
<p>SH600519è´µå·èŒ…å°çš„æ—¥kçº¿æ•°æ®</p>
<figure data-type="image" tabindex="9"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191231566-9.png" alt="6-9" loading="lazy"></figure>
<p>åªç”¨cåˆ—æ•°æ®ï¼Œè¿ç»­60å¤©å¼€ç›˜ä»·é¢„æµ‹ç¬¬61å¤©çš„å¼€ç›˜ä»·ã€‚</p>
<p>ä¸‹è½½ä»£ç ï¼š</p>
<pre><code class="language-python">import tushare as ts
import matplotlib.pyplot as plt

df1 = ts.get_k_data('600519', ktype='D', start='2010-04-26', end='2020-04-26')

datapath1 = &quot;./SH600519.csv&quot;
df1.to_csv(datapath1)
</code></pre>
</li>
<li>
<p>RNNå®ç°è‚¡ç¥¨é¢„æµ‹ä»£ç </p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dropout, Dense, SimpleRNN
import matplotlib.pyplot as plt
import os
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import math

maotai = pd.read_csv('./SH600519.csv')  # è¯»å–è‚¡ç¥¨æ–‡ä»¶

training_set = maotai.iloc[0:2426 - 300, 2:3].values  # å‰(2426-300=2126)å¤©çš„å¼€ç›˜ä»·ä½œä¸ºè®­ç»ƒé›†,è¡¨æ ¼ä»0å¼€å§‹è®¡æ•°ï¼Œ2:3 æ˜¯æå–[2:3)åˆ—ï¼Œå‰é—­åå¼€,æ•…æå–å‡ºCåˆ—å¼€ç›˜ä»·
test_set = maotai.iloc[2426 - 300:, 2:3].values  # å300å¤©çš„å¼€ç›˜ä»·ä½œä¸ºæµ‹è¯•é›†

# å½’ä¸€åŒ–
sc = MinMaxScaler(feature_range=(0, 1))  # å®šä¹‰å½’ä¸€åŒ–ï¼šå½’ä¸€åŒ–åˆ°(0ï¼Œ1)ä¹‹é—´
training_set_scaled = sc.fit_transform(training_set)  # æ±‚å¾—è®­ç»ƒé›†çš„æœ€å¤§å€¼ï¼Œæœ€å°å€¼è¿™äº›è®­ç»ƒé›†å›ºæœ‰çš„å±æ€§ï¼Œå¹¶åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œå½’ä¸€åŒ–
test_set = sc.transform(test_set)  # åˆ©ç”¨è®­ç»ƒé›†çš„å±æ€§å¯¹æµ‹è¯•é›†è¿›è¡Œå½’ä¸€åŒ–

x_train = []
y_train = []

x_test = []
y_test = []

# æµ‹è¯•é›†ï¼šcsvè¡¨æ ¼ä¸­å‰2426-300=2126å¤©æ•°æ®
# åˆ©ç”¨forå¾ªç¯ï¼Œéå†æ•´ä¸ªè®­ç»ƒé›†ï¼Œæå–è®­ç»ƒé›†ä¸­è¿ç»­60å¤©çš„å¼€ç›˜ä»·ä½œä¸ºè¾“å…¥ç‰¹å¾x_trainï¼Œç¬¬61å¤©çš„æ•°æ®ä½œä¸ºæ ‡ç­¾ï¼Œforå¾ªç¯å…±æ„å»º2426-300-60=2066ç»„æ•°æ®ã€‚
for i in range(60, len(training_set_scaled)):
    x_train.append(training_set_scaled[i - 60:i, 0])
    y_train.append(training_set_scaled[i, 0])
# å¯¹è®­ç»ƒé›†è¿›è¡Œæ‰“ä¹±
np.random.seed(7)
np.random.shuffle(x_train)
np.random.seed(7)
np.random.shuffle(y_train)
tf.random.set_seed(7)
# å°†è®­ç»ƒé›†ç”±listæ ¼å¼å˜ä¸ºarrayæ ¼å¼
x_train, y_train = np.array(x_train), np.array(y_train)

# ä½¿x_trainç¬¦åˆRNNè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ï¼Œ æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]ã€‚
# æ­¤å¤„æ•´ä¸ªæ•°æ®é›†é€å…¥ï¼Œé€å…¥æ ·æœ¬æ•°ä¸ºx_train.shape[0]å³2066ç»„æ•°æ®ï¼›è¾“å…¥60ä¸ªå¼€ç›˜ä»·ï¼Œé¢„æµ‹å‡ºç¬¬61å¤©çš„å¼€ç›˜ä»·ï¼Œå¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ä¸º60; æ¯ä¸ªæ—¶é—´æ­¥é€å…¥çš„ç‰¹å¾æ˜¯æŸä¸€å¤©çš„å¼€ç›˜ä»·ï¼Œåªæœ‰1ä¸ªæ•°æ®ï¼Œæ•…æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°ä¸º1
x_train = np.reshape(x_train, (x_train.shape[0], 60, 1))
# æµ‹è¯•é›†ï¼šcsvè¡¨æ ¼ä¸­å300å¤©æ•°æ®
# åˆ©ç”¨forå¾ªç¯ï¼Œéå†æ•´ä¸ªæµ‹è¯•é›†ï¼Œæå–æµ‹è¯•é›†ä¸­è¿ç»­60å¤©çš„å¼€ç›˜ä»·ä½œä¸ºè¾“å…¥ç‰¹å¾x_trainï¼Œç¬¬61å¤©çš„æ•°æ®ä½œä¸ºæ ‡ç­¾ï¼Œforå¾ªç¯å…±æ„å»º300-60=240ç»„æ•°æ®ã€‚
for i in range(60, len(test_set)):
    x_test.append(test_set[i - 60:i, 0])
    y_test.append(test_set[i, 0])
# æµ‹è¯•é›†å˜arrayå¹¶reshapeä¸ºç¬¦åˆRNNè¾“å…¥è¦æ±‚ï¼š[é€å…¥æ ·æœ¬æ•°ï¼Œ å¾ªç¯æ ¸æ—¶é—´å±•å¼€æ­¥æ•°ï¼Œ æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥ç‰¹å¾ä¸ªæ•°]
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], 60, 1))

model = tf.keras.Sequential([
    SimpleRNN(80, return_sequences=True),
    Dropout(0.2),
    SimpleRNN(100),
    Dropout(0.2),
    Dense(1)
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
              loss='mean_squared_error')  # æŸå¤±å‡½æ•°ç”¨å‡æ–¹è¯¯å·®
# è¯¥åº”ç”¨åªè§‚æµ‹lossæ•°å€¼ï¼Œä¸è§‚æµ‹å‡†ç¡®ç‡ï¼Œæ‰€ä»¥åˆ å»metricsé€‰é¡¹ï¼Œä¸€ä¼šåœ¨æ¯ä¸ªepochè¿­ä»£æ˜¾ç¤ºæ—¶åªæ˜¾ç¤ºlosså€¼

checkpoint_save_path = &quot;./checkpoint/rnn_stock.ckpt&quot;

if os.path.exists(checkpoint_save_path + '.index'):
    print('-------------load the model-----------------')
    model.load_weights(checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True,
                                                 monitor='val_loss')

history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), validation_freq=1,
                    callbacks=[cp_callback])

model.summary()

file = open('./weights.txt', 'w')  # å‚æ•°æå–
for v in model.trainable_variables:
    file.write(str(v.name) + '\n')
    file.write(str(v.shape) + '\n')
    file.write(str(v.numpy()) + '\n')
file.close()

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

################## predict ######################
# æµ‹è¯•é›†è¾“å…¥æ¨¡å‹è¿›è¡Œé¢„æµ‹
predicted_stock_price = model.predict(x_test)
# å¯¹é¢„æµ‹æ•°æ®è¿˜åŸ---ä»ï¼ˆ0ï¼Œ1ï¼‰åå½’ä¸€åŒ–åˆ°åŸå§‹èŒƒå›´
predicted_stock_price = sc.inverse_transform(predicted_stock_price)
# å¯¹çœŸå®æ•°æ®è¿˜åŸ---ä»ï¼ˆ0ï¼Œ1ï¼‰åå½’ä¸€åŒ–åˆ°åŸå§‹èŒƒå›´
real_stock_price = sc.inverse_transform(test_set[60:])
# ç”»å‡ºçœŸå®æ•°æ®å’Œé¢„æµ‹æ•°æ®çš„å¯¹æ¯”æ›²çº¿
plt.plot(real_stock_price, color='red', label='MaoTai Stock Price')
plt.plot(predicted_stock_price, color='blue', label='Predicted MaoTai Stock Price')
plt.title('MaoTai Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('MaoTai Stock Price')
plt.legend()
plt.show()

##########evaluate##############
# calculate MSE å‡æ–¹è¯¯å·® ---&gt; E[(é¢„æµ‹å€¼-çœŸå®å€¼)^2] (é¢„æµ‹å€¼å‡çœŸå®å€¼æ±‚å¹³æ–¹åæ±‚å‡å€¼)
mse = mean_squared_error(predicted_stock_price, real_stock_price)
# calculate RMSE å‡æ–¹æ ¹è¯¯å·®---&gt;sqrt[MSE]    (å¯¹å‡æ–¹è¯¯å·®å¼€æ–¹)
rmse = math.sqrt(mean_squared_error(predicted_stock_price, real_stock_price))
# calculate MAE å¹³å‡ç»å¯¹è¯¯å·®-----&gt;E[|é¢„æµ‹å€¼-çœŸå®å€¼|](é¢„æµ‹å€¼å‡çœŸå®å€¼æ±‚ç»å¯¹å€¼åæ±‚å‡å€¼ï¼‰
mae = mean_absolute_error(predicted_stock_price, real_stock_price)
print('å‡æ–¹è¯¯å·®: %.6f' % mse)
print('å‡æ–¹æ ¹è¯¯å·®: %.6f' % rmse)
print('å¹³å‡ç»å¯¹è¯¯å·®: %.6f' % mae)


# è¿è¡Œç»“æœ
# Epoch 50/50
# 33/33 [==============================] - 2s 70ms/step - loss: 0.0011 - val_loss: 0.0081
# Model: &quot;sequential&quot;
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #   
# =================================================================
# simple_rnn (SimpleRNN)       (None, 60, 80)            6560      
# _________________________________________________________________
# dropout (Dropout)            (None, 60, 80)            0         
# _________________________________________________________________
# simple_rnn_1 (SimpleRNN)     (None, 100)               18100     
# _________________________________________________________________
# dropout_1 (Dropout)          (None, 100)               0         
# _________________________________________________________________
# dense (Dense)                (None, 1)                 101       
# =================================================================
# Total params: 24,761
# Trainable params: 24,761
# Non-trainable params: 0
# _________________________________________________________________
# å‡æ–¹è¯¯å·®: 4064.439908
# å‡æ–¹æ ¹è¯¯å·®: 63.752960
# å¹³å‡ç»å¯¹è¯¯å·®: 59.361609
</code></pre>
</li>
<li>
<p>LSTMå®ç°è‚¡ç¥¨é¢„æµ‹</p>
<p>ä¼ ç»Ÿå¾ªç¯ç½‘ç»œRNNï¼Œå¯ä»¥é€šè¿‡è®°å¿†ä½“å®ç°çŸ­æœŸè®°å¿†è¿›è¡Œè¿ç»­æ•°æ®çš„é¢„æµ‹ã€‚ä½†æ˜¯å½“è¿ç»­æ•°æ®çš„åºåˆ—å˜é•¿æ—¶ï¼Œä¼šä½¿å±•å¼€æ—¶é—´æ­¥è¿‡é•¿ã€‚åœ¨åå‘ä¼ æ’­æ›´æ–°å‚æ•°æ—¶ï¼Œæ¢¯åº¦è¦æŒ‰ç…§æ—¶é—´æ­¥è¿ç»­ç›¸ä¹˜ï¼Œä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚</p>
<blockquote>
<p>LSTM ç”±Hochreiter &amp; Schmidhuber äº1997å¹´æå‡ºï¼Œé€šè¿‡é—¨æ§å•å…ƒæ”¹å–„äº†RNNé•¿æœŸä¾èµ–é—®é¢˜ã€‚ Sepp Hochreiter,Jurgen Schmidhuber.LONG SHORT-TERM MEMORY.Neural Computation,December 1997.</p>
</blockquote>
<figure data-type="image" tabindex="10"><img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191232006-10.png" alt="6-10" loading="lazy"></figure>
<p>ä¸‰ä¸ªé—¨é™å…¬å¼ä¸­<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">W_i, W_f, W_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">o</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>æ˜¯å¾…è®­ç»ƒå‚æ•°çŸ©é˜µï¼Œ<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">b_i, b_f, b_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">o</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>æ˜¯å¾…è®­ç»ƒåç½®é¡¹ã€‚ç»è¿‡sigmoidå‡½æ•°åï¼Œä½¿é—¨é™èŒƒå›´åœ¨[0, 1]ä¹‹é—´ã€‚</p>
<p>å½“æœ‰å¤šå±‚å¾ªç¯ç½‘ç»œæ—¶ï¼Œç¬¬äºŒå±‚å¾ªç¯ç½‘ç»œçš„è¾“å…¥<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>å°±æ˜¯ç¬¬ä¸€å±‚å¾ªç¯ç½‘ç»œçš„è¾“å‡º<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>ã€‚ï¼ˆè¾“å…¥ç¬¬äºŒå±‚ç½‘ç»œçš„æ˜¯<strong>ç¬¬ä¸€å±‚</strong>ç½‘ç»œæå–å‡ºçš„ç²¾åï¼‰</p>
</li>
<li>
<p>TFæè¿°LSTMå±‚</p>
<pre><code class="language-python">tf.keras.layers.LSTM(è®°å¿†ä½“ä¸ªæ•°, return_sequences=æ˜¯å¦è¿”å›è¾“å‡º)
return_sequences=True  # å„æ—¶é—´æ­¥è¾“å‡ºht
return_sequences=False  # ä»…æœ€åæ—¶é—´æ­¥è¾“å‡ºhtï¼ˆé»˜è®¤ï¼‰
# ä¸€èˆ¬æœ€åä¸€å±‚ç”¨Fasleï¼Œå…¶ä»–å±‚ç”¨True
</code></pre>
<p>Example:</p>
<pre><code class="language-python">model = tf.keras.Sequential([
    LSTM(80, return_sequences=True),  # å„æ—¶é—´æ­¥è¾“å‡ºht
    Dropout(0.2),
    LSTM(100),  # ä»…æœ€åæ—¶é—´æ­¥è¾“å‡ºhtï¼ˆé»˜è®¤ï¼‰
    Dropout(0.2),
    Dense(1)
])
</code></pre>
</li>
<li>
<p>LSTMå®ç°è‚¡ç¥¨é¢„æµ‹çš„ä»£ç </p>
<p>ä»…å±•ç¤ºä¸ä¸Šä¸€ä»£ç ï¼ˆp38ï¼‰ä¸åŒä¹‹å¤„:</p>
<pre><code class="language-python">from tensorflow.keras.layers import Dropout, Dense, LSTM

model = tf.keras.Sequential([
    LSTM(80, return_sequences=True),  # å„æ—¶é—´æ­¥è¾“å‡ºht
    Dropout(0.2),
    LSTM(100),  # ä»…æœ€åæ—¶é—´æ­¥è¾“å‡ºhtï¼ˆé»˜è®¤ï¼‰
    Dropout(0.2),
    Dense(1)
])
</code></pre>
</li>
<li>
<p>ç”¨GRUå®ç°è‚¡ç¥¨é¢„æµ‹</p>
<blockquote>
<p>GRUç”±Choç­‰äººäº2014å¹´æå‡ºï¼Œä¼˜åŒ–LSTMç»“æ„ã€‚ Kyunghyun Cho,Bart van Merrienboer,Caglar Gulcehre,Dzmitry Bahdanau,Fethi Bougares,Holger  Schwenk,Yoshua Bengio.Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical  Machine Translation.Computer ence, 2014.</p>
</blockquote>
<p>GRUè®¡ç®—è¿‡ç¨‹<br>
<img src="https://images.cnblogs.com/cnblogs_com/ache/1998711/o_2107191232056-11.png" alt="6-11" loading="lazy"></p>
<p>ä¸¤ä¸ªé—¨é™å–å€¼èŒƒå›´ä¹Ÿæ˜¯[0, 1]ï¼Œå‰å‘ä¼ æ’­æ—¶å€™ï¼Œä½¿ç”¨è®°å¿†ä½“æ›´æ–°å…¬å¼ä½“å°±å¯ä»¥ç®—å‡ºæ¯ä¸ªæ—¶åˆ»çš„<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>å€¼äº†ã€‚</p>
</li>
<li>
<p>TFæè¿°GRUå±‚</p>
<pre><code class="language-python">tf.keras.layers.GRU(è®°å¿†ä½“ä¸ªæ•°, return_sequences=æ˜¯å¦è¿”å›è¾“å‡º)
return_sequences=True  # å„æ—¶é—´æ­¥è¾“å‡ºht
return_sequences=False  # ä»…æœ€åæ—¶é—´æ­¥è¾“å‡ºhtï¼ˆé»˜è®¤ï¼‰
# ä¸€èˆ¬æœ€åä¸€å±‚ç”¨Fasleï¼Œå…¶ä»–å±‚ç”¨True
</code></pre>
<p>Example</p>
<pre><code class="language-python">model = tf.keras.Sequential([
    GRU(80, return_sequences=True),  # æ¯ä¸ªæ—¶é—´æ­¥è¾“å‡ºht
    Dropout(0.2),
    GRU(100),  # ä»…æœ€åæ—¶é—´æ­¥è¾“å‡ºhtï¼ˆé»˜è®¤ï¼‰
    Dropout(0.2),
    Dense(1)
])
</code></pre>
</li>
<li>
<p>GRUå®ç°è‚¡ç¥¨é¢„æµ‹çš„ä»£ç </p>
<p>ä»…å±•ç¤ºä¸ä¸Šä¸Šä¸ªä»£ç ï¼ˆp38ï¼‰ä¸åŒä¹‹å¤„:</p>
<pre><code class="language-python">from tensorflow.keras.layers import Dropout, Dense, GRU

model = tf.keras.Sequential([
    GRU(80, return_sequences=True),
    Dropout(0.2),
    GRU(100),
    Dropout(0.2),
    Dense(1)
])
</code></pre>
</li>
</ul>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://perfectqing.github.io/blogs/tag/S2mqBZ0HP/" class="tag">
                    TensorFlow ç¬”è®°
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">ä¸‹ä¸€ç¯‡</div>
                <a href="https://perfectqing.github.io/blogs/post/ç¬¬äº”ç«  ç¥ç»ç½‘ç»œå·ç§¯è®¡ç®—/">
                  <h3 class="post-title">
                    ç¬¬äº”ç«  ç¥ç»ç½‘ç»œå·ç§¯è®¡ç®—
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>


  <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  <script>
    hljs.initHighlightingOnLoad()
  </script>





  </body>
</html>
